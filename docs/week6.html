<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Week 6: Scaling Techniques and Topic Modeling | PS9594: Computational Text Analysis</title>
<meta name="author" content="Dr. Sebastián Vallejo Vera | Western University">
<meta name="description" content="Slides 6 Scaling Techniques and Topic Modeling (link to slides)  6.1 Setup As always, we first load the packages that we’ll be using: library(tidyverse) # for wrangling data library(tidylog) # to...">
<meta name="generator" content="bookdown 0.42 with bs4_book()">
<meta property="og:title" content="Chapter 6 Week 6: Scaling Techniques and Topic Modeling | PS9594: Computational Text Analysis">
<meta property="og:type" content="book">
<meta property="og:description" content="Slides 6 Scaling Techniques and Topic Modeling (link to slides)  6.1 Setup As always, we first load the packages that we’ll be using: library(tidyverse) # for wrangling data library(tidylog) # to...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Week 6: Scaling Techniques and Topic Modeling | PS9594: Computational Text Analysis">
<meta name="twitter:description" content="Slides 6 Scaling Techniques and Topic Modeling (link to slides)  6.1 Setup As always, we first load the packages that we’ll be using: library(tidyverse) # for wrangling data library(tidylog) # to...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">PS9594: Computational Text Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">“Computational Text Analysis”</a></li>
<li><a class="" href="readings.html">Reading List</a></li>
<li><a class="" href="assignments.html">Assignments</a></li>
<li><a class="" href="replication.html">Replication Exercise</a></li>
<li><a class="" href="final_paper.html">Final Paper</a></li>
<li><a class="" href="week1.html"><span class="header-section-number">1</span> Week 1: A Primer on Using Text as Data</a></li>
<li><a class="" href="week2.html"><span class="header-section-number">2</span> Week 2: Tokenization and Word Frequency</a></li>
<li><a class="" href="week3.html"><span class="header-section-number">3</span> Week 3: Dictionary-Based Approaches</a></li>
<li><a class="" href="week4.html"><span class="header-section-number">4</span> Week 4: Complexity and Similarity</a></li>
<li><a class="" href="week5.html"><span class="header-section-number">5</span> Week 5: Scaling Techniques (Unsupervised Learning I)</a></li>
<li><a class="active" href="week6.html"><span class="header-section-number">6</span> Week 6: Scaling Techniques and Topic Modeling</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/svallejovera/cta_updated">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="week6" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Week 6: Scaling Techniques and Topic Modeling<a class="anchor" aria-label="anchor" href="#week6"><i class="fas fa-link"></i></a>
</h1>
<div id="slides-5" class="section level2 unnumbered">
<h2>Slides<a class="anchor" aria-label="anchor" href="#slides-5"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>6 Scaling Techniques and Topic Modeling (<a href="https://github.com/svallejovera/cta_updated/blob/main/slides/6%20Scaling%20Techniques%20and%20Topic%20Modeling.pptx">link</a> to slides)</li>
</ul>
</div>
<div id="setup-5" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Setup<a class="anchor" aria-label="anchor" href="#setup-5"><i class="fas fa-link"></i></a>
</h2>
<p>As always, we first load the packages that we’ll be using:</p>
<div class="sourceCode" id="cb182"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span> <span class="co"># for wrangling data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/elbersb/tidylog/">tidylog</a></span><span class="op">)</span> <span class="co"># to know what we are wrangling</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://juliasilge.github.io/tidytext/">tidytext</a></span><span class="op">)</span> <span class="co"># for 'tidy' manipulation of text data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://quanteda.io">quanteda</a></span><span class="op">)</span> <span class="co"># tokenization power house</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/quanteda/quanteda.textmodels">quanteda.textmodels</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.structuraltopicmodel.com/">stm</a></span><span class="op">)</span> <span class="co"># run structural topic models</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/karthik/wesanderson">wesanderson</a></span><span class="op">)</span> <span class="co"># to prettify</span></span></code></pre></div>
<p>We get the data from the inaugural speeches again.</p>
<div class="sourceCode" id="cb183"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">us_pres</span> <span class="op">&lt;-</span> <span class="fu">readxl</span><span class="fu">::</span><span class="fu"><a href="https://readxl.tidyverse.org/reference/read_excel.html">read_xlsx</a></span><span class="op">(</span>path <span class="op">=</span> <span class="st">"data/inaugTexts.xlsx"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">us_pres</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 6 × 4
##   inaugSpeech                                        Year President party
##   &lt;chr&gt;                                             &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;
## 1 "My Countrymen, It a relief to feel that no hear…  1853 Pierce    Demo…
## 2 "Fellow citizens, I appear before you this day t…  1857 Buchanan  Demo…
## 3 "Fellow-Citizens of the United States: In compli…  1861 Lincoln   Repu…
## 4 "Fellow-Countrymen:\r\n\r\nAt this second appear…  1865 Lincoln   Repu…
## 5 "Citizens of the United States:\r\n\r\nYour suff…  1869 Grant     Repu…
## 6 "Fellow-Citizens:\r\n\r\nUnder Providence I have…  1873 Grant     Repu…</code></pre>
<p>The text is pretty clean, so we can convert it into a corpus object, then into a <code>dfm</code>:</p>
<div class="sourceCode" id="cb185"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">corpus_us_pres</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/corpus.html">corpus</a></span><span class="op">(</span><span class="va">us_pres</span>,</span>
<span>                     text_field <span class="op">=</span> <span class="st">"inaugSpeech"</span>,</span>
<span>                     unique_docnames <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">corpus_us_pres</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Corpus consisting of 41 documents, showing 41 documents:
## 
##    Text Types Tokens Sentences Year    President      party
##   text1  1164   3631       104 1853       Pierce   Democrat
##   text2   944   3080        89 1857     Buchanan   Democrat
##   text3  1074   3992       135 1861      Lincoln Republican
##   text4   359    774        26 1865      Lincoln Republican
##   text5   484   1223        40 1869        Grant Republican
##   text6   551   1469        43 1873        Grant Republican
##   text7   830   2698        59 1877        Hayes Republican
##   text8  1020   3206       111 1881     Garfield Republican
##   text9   675   1812        44 1885    Cleveland   Democrat
##  text10  1351   4720       157 1889     Harrison Republican
##  text11   821   2125        58 1893    Cleveland   Democrat
##  text12  1231   4345       130 1897     McKinley Republican
##  text13   854   2437       100 1901     McKinley Republican
##  text14   404   1079        33 1905  T Roosevelt Republican
##  text15  1437   5822       158 1909         Taft Republican
##  text16   658   1882        68 1913       Wilson   Democrat
##  text17   548   1648        59 1917       Wilson   Democrat
##  text18  1168   3717       148 1921      Harding Republican
##  text19  1220   4440       196 1925     Coolidge Republican
##  text20  1089   3855       158 1929       Hoover Republican
##  text21   742   2052        85 1933 FD Roosevelt   Democrat
##  text22   724   1981        96 1937 FD Roosevelt   Democrat
##  text23   525   1494        68 1941 FD Roosevelt   Democrat
##  text24   274    619        27 1945 FD Roosevelt   Democrat
##  text25   780   2495       116 1949       Truman   Democrat
##  text26   899   2729       119 1953   Eisenhower Republican
##  text27   620   1883        92 1957   Eisenhower Republican
##  text28   565   1516        52 1961      Kennedy   Democrat
##  text29   567   1697        93 1965      Johnson   Democrat
##  text30   742   2395       103 1969        Nixon Republican
##  text31   543   1978        68 1973        Nixon Republican
##  text32   527   1364        52 1977       Carter   Democrat
##  text33   902   2772       129 1981       Reagan Republican
##  text34   924   2897       124 1985       Reagan Republican
##  text35   795   2667       141 1989         Bush Republican
##  text36   642   1833        81 1993      Clinton   Democrat
##  text37   772   2423       111 1997      Clinton   Democrat
##  text38   620   1804        97 2001         Bush Republican
##  text39   773   2321       100 2005         Bush Republican
##  text40   937   2667       110 2009        Obama   Democrat
##  text41   814   2317        88 2013        Obama   Democrat</code></pre>
<div class="sourceCode" id="cb187"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># We do the whole tokenization sequence</span></span>
<span><span class="va">toks_us_pres</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/tokens.html">tokens</a></span><span class="op">(</span><span class="va">corpus_us_pres</span>,</span>
<span>                   remove_numbers <span class="op">=</span> <span class="cn">TRUE</span>, <span class="co"># Thinks about this</span></span>
<span>                   remove_punct <span class="op">=</span> <span class="cn">TRUE</span>, <span class="co"># Remove punctuation!</span></span>
<span>                   remove_url <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="co"># Might be helpful</span></span>
<span></span>
<span><span class="va">toks_us_pres</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/tokens_select.html">tokens_remove</a></span><span class="op">(</span><span class="va">toks_us_pres</span>,</span>
<span>                              <span class="co"># Should we though? See Denny and Spirling (2018)</span></span>
<span>                              <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/stopwords/man/stopwords.html">stopwords</a></span><span class="op">(</span>language <span class="op">=</span> <span class="st">"en"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                              padding <span class="op">=</span> <span class="cn">F</span><span class="op">)</span></span>
<span></span>
<span><span class="va">toks_us_pres</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/tokens_wordstem.html">tokens_wordstem</a></span><span class="op">(</span><span class="va">toks_us_pres</span>, language <span class="op">=</span> <span class="st">"en"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dfm_us_pres</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/dfm.html">dfm</a></span><span class="op">(</span><span class="va">toks_us_pres</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="structural-topic-models" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Structural Topic Models<a class="anchor" aria-label="anchor" href="#structural-topic-models"><i class="fas fa-link"></i></a>
</h2>
<p>STM provides two ways to include contextual information to “guide” model estimation. First, <strong>topic prevalence</strong> can vary by metadata (e.g., Republicans talk about military issues more than Democrats). Second, <strong>topic content</strong> can vary by metadata (e.g., Republicans talk about military issues differently from Democrats).</p>
<p>We can run STM using the <code>stm</code> package. The package includes a complete workflow (i.e., from raw text to figures), and if you are planning to use it in the future, I highly encourage you to check <a href="https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf">this</a>, <a href="https://www.jstor.org/stable/pdf/24363543.pdf?casa_token=b_rJjIOUUScAAAAA:KXNQeVBQMzB7-kIEhl-1qo6uyD7vHvRTHhMinMdZVT6G3M3olzKzPv00XMJQd7mRw9Nm9UqJDmWHv3N_0cXBmbdeu2XZv8-jy1RYxvpm7Ab3WEOmApXP">this</a>, <a href="https://juliasilge.com/blog/evaluating-stm/">this</a>, and <a href="https://juliasilge.com/blog/sherlock-holmes-stm/">this</a>.</p>
<p>At a high level, <code><a href="https://rdrr.io/pkg/stm/man/stm.html">stm()</a></code> takes our <em>dfm</em> and produces topics. If we do not specify any prevalence terms, it will estimate an LDA-style model. Because this is a Bayesian approach, it is recommended that you set a seed value for replication. We also need to choose <span class="math inline">\(K\)</span>, the number of topics. How many topics is the “right” number? There is no good number. Too many pre-specified topics and the categories might be meaningless. Too few, and you might be piling together two or more topics. Note that changes to a) the number of topics, b) the prevalence term, c) the omitted words, d) the seed value, can (greatly) change the outcome. Here is where validation becomes crucial (for a review see <a href="https://www.researchgate.net/profile/Andreu_Casas/publication/317140610_Large-Scale_Computerized_Text_Analysis_in_Political_Science_Opportunities_and_Challenges/links/59285e6f0f7e9b9979a35ec4/Large-Scale-Computerized-Text-Analysis-in-Political-Science-Opportunities-and-Challenges.pdf">Wilkerson and Casas 2017</a>).</p>
<p>Using our presidential speeches data, I will use <code>stm</code> to estimate topics in inaugural addresses. As the prevalence term, I include the party of the speaker. I set the number of topics to 10 (but with a corpus this large, I would likely start around ~30 and work my way up from there).</p>
<div class="sourceCode" id="cb188"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">stm_us_pres</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/stm/man/stm.html">stm</a></span><span class="op">(</span><span class="va">dfm_us_pres</span>, K <span class="op">=</span> <span class="fl">10</span>, seed <span class="op">=</span> <span class="fl">1984</span>,</span>
<span>                   prevalence <span class="op">=</span> <span class="op">~</span><span class="va">party</span>,</span>
<span>                   init.type <span class="op">=</span> <span class="st">"Spectral"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Beginning Spectral Initialization 
##   Calculating the gram matrix...
##   Finding anchor words...
##      ..........
##   Recovering initialization...
##      ..............................................
## Initialization complete.
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 1 (approx. per word bound = -7.071) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 2 (approx. per word bound = -6.881, relative change = 2.687e-02) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 3 (approx. per word bound = -6.819, relative change = 8.982e-03) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 4 (approx. per word bound = -6.790, relative change = 4.255e-03) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 5 (approx. per word bound = -6.780, relative change = 1.524e-03) 
## Topic 1: us, new, world, nation, let 
##  Topic 2: new, can, us, nation, work 
##  Topic 3: constitut, state, union, can, law 
##  Topic 4: nation, must, us, peopl, can 
##  Topic 5: govern, peopl, upon, state, law 
##  Topic 6: nation, freedom, america, govern, peopl 
##  Topic 7: us, america, must, nation, american 
##  Topic 8: upon, nation, govern, peopl, shall 
##  Topic 9: world, nation, peopl, peac, can 
##  Topic 10: us, nation, govern, must, peopl 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 6 (approx. per word bound = -6.775, relative change = 7.006e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 7 (approx. per word bound = -6.771, relative change = 5.509e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 8 (approx. per word bound = -6.767, relative change = 5.381e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 9 (approx. per word bound = -6.765, relative change = 4.264e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 10 (approx. per word bound = -6.763, relative change = 2.933e-04) 
## Topic 1: us, new, world, let, nation 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, union, can, shall 
##  Topic 4: nation, must, peopl, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, peopl, govern 
##  Topic 7: us, america, must, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, world, peopl, peac, can 
##  Topic 10: us, govern, nation, peopl, must 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 11 (approx. per word bound = -6.761, relative change = 2.052e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 12 (approx. per word bound = -6.760, relative change = 1.718e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 13 (approx. per word bound = -6.759, relative change = 1.451e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 14 (approx. per word bound = -6.758, relative change = 1.120e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 15 (approx. per word bound = -6.758, relative change = 9.982e-05) 
## Topic 1: us, new, let, world, nation 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, union, can, shall 
##  Topic 4: nation, must, peopl, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, peopl, govern 
##  Topic 7: us, america, must, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, peopl, world, can, peac 
##  Topic 10: us, govern, nation, peopl, must 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 16 (approx. per word bound = -6.757, relative change = 1.013e-04) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 17 (approx. per word bound = -6.756, relative change = 8.202e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 18 (approx. per word bound = -6.756, relative change = 6.758e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 19 (approx. per word bound = -6.756, relative change = 4.870e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 20 (approx. per word bound = -6.755, relative change = 3.674e-05) 
## Topic 1: us, new, let, world, nation 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, govern, peopl, shall 
##  Topic 4: nation, must, peopl, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, peopl, govern 
##  Topic 7: us, must, america, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, peopl, world, can, peac 
##  Topic 10: us, govern, nation, peopl, must 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 21 (approx. per word bound = -6.755, relative change = 3.567e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 22 (approx. per word bound = -6.755, relative change = 3.498e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 23 (approx. per word bound = -6.755, relative change = 3.208e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 24 (approx. per word bound = -6.754, relative change = 3.402e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 25 (approx. per word bound = -6.754, relative change = 3.194e-05) 
## Topic 1: us, new, let, world, nation 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, govern, peopl, shall 
##  Topic 4: nation, must, peopl, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, govern, peopl 
##  Topic 7: us, must, america, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, peopl, world, can, peac 
##  Topic 10: us, govern, nation, peopl, must 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 26 (approx. per word bound = -6.754, relative change = 2.748e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 27 (approx. per word bound = -6.754, relative change = 2.585e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 28 (approx. per word bound = -6.754, relative change = 2.739e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 29 (approx. per word bound = -6.753, relative change = 4.431e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 30 (approx. per word bound = -6.753, relative change = 2.313e-05) 
## Topic 1: us, new, let, nation, world 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, govern, peopl, shall 
##  Topic 4: nation, peopl, must, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, govern, peopl 
##  Topic 7: us, must, america, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, peopl, world, can, peac 
##  Topic 10: us, govern, nation, peopl, world 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 31 (approx. per word bound = -6.753, relative change = 1.789e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 32 (approx. per word bound = -6.753, relative change = 1.825e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 33 (approx. per word bound = -6.753, relative change = 1.667e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 34 (approx. per word bound = -6.753, relative change = 1.600e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 35 (approx. per word bound = -6.753, relative change = 1.738e-05) 
## Topic 1: us, new, let, nation, world 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, govern, peopl, shall 
##  Topic 4: nation, peopl, must, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, govern, peopl 
##  Topic 7: us, must, america, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, peopl, world, can, peac 
##  Topic 10: us, govern, nation, peopl, world 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 36 (approx. per word bound = -6.752, relative change = 1.979e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 37 (approx. per word bound = -6.752, relative change = 2.035e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 38 (approx. per word bound = -6.752, relative change = 1.686e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 39 (approx. per word bound = -6.752, relative change = 1.478e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 40 (approx. per word bound = -6.752, relative change = 1.269e-05) 
## Topic 1: us, new, let, nation, world 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, govern, peopl, shall 
##  Topic 4: nation, peopl, must, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, govern, peopl 
##  Topic 7: us, must, america, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, peopl, world, can, peac 
##  Topic 10: us, govern, nation, peopl, world 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 41 (approx. per word bound = -6.752, relative change = 1.409e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 42 (approx. per word bound = -6.752, relative change = 1.433e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 43 (approx. per word bound = -6.752, relative change = 2.066e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 44 (approx. per word bound = -6.752, relative change = 2.418e-05) 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Completing Iteration 45 (approx. per word bound = -6.751, relative change = 1.609e-05) 
## Topic 1: us, new, let, nation, world 
##  Topic 2: us, new, can, nation, work 
##  Topic 3: constitut, state, govern, peopl, shall 
##  Topic 4: nation, peopl, must, us, world 
##  Topic 5: govern, peopl, upon, law, state 
##  Topic 6: nation, freedom, america, peopl, govern 
##  Topic 7: us, must, america, nation, american 
##  Topic 8: upon, nation, govern, peopl, can 
##  Topic 9: nation, peopl, world, can, peac 
##  Topic 10: us, govern, nation, peopl, world 
## .........................................
## Completed E-Step (0 seconds). 
## Completed M-Step. 
## Model Converged</code></pre>
<p>The nice thing about the <code><a href="https://rdrr.io/pkg/stm/man/stm.html">stm()</a></code> function is that it allows us to see, in “real time,” what is going on inside the black box. We can summarize the process as follows (this is similar to collapsed Gibbs sampling, which <code><a href="https://rdrr.io/pkg/stm/man/stm.html">stm()</a></code> sort of uses):</p>
<ol style="list-style-type: decimal">
<li><p>Go through each document and randomly assign each word in the document to one of the topics, <span class="math inline">\(\displaystyle t \in k\)</span>.</p></li>
<li><p>Notice that this random assignment already gives topic representations for all documents and word distributions for all topics (albeit not very good ones).</p></li>
<li>
<p>To improve these estimates, for each document <span class="math inline">\(\displaystyle W\)</span>, do the following:</p>
<p>3.1 Go through each word <span class="math inline">\(\displaystyle w\)</span> in <span class="math inline">\(\displaystyle W\)</span>.</p>
<p>3.1.1 For each topic <span class="math inline">\(\displaystyle t\)</span>, compute two quantities:</p>
<p>3.1.1.1 <span class="math inline">\(\displaystyle p(t \mid W)\)</span>: the proportion of words in document <span class="math inline">\(\displaystyle W\)</span> that are currently assigned to topic <span class="math inline">\(\displaystyle t\)</span>; and</p>
<p>3.1.1.2 <span class="math inline">\(\displaystyle p(w \mid t)\)</span>: the proportion of assignments to topic <span class="math inline">\(\displaystyle t\)</span> (across all documents) that come from the word <span class="math inline">\(\displaystyle w\)</span>.</p>
<p>Reassign <span class="math inline">\(\displaystyle w\)</span> to a new topic by choosing topic <span class="math inline">\(\displaystyle t\)</span> with probability <span class="math inline">\(\displaystyle p(t \mid W)\, p(w \mid t)\)</span>. Under the generative model, this is essentially the probability that topic <span class="math inline">\(\displaystyle t\)</span> generated word <span class="math inline">\(\displaystyle w\)</span>, so it makes sense to resample the current word’s topic using this probability. (I’m glossing over a couple of details here—most notably the use of priors/pseudocounts in these probabilities.)</p>
<p>3.1.1.3 In other words, at this step we assume that all topic assignments except for the current word are correct, and then update the assignment of the current word using our model of how documents are generated.</p>
</li>
<li><p>After repeating the previous step many times, you eventually reach a roughly steady state where the assignments are reasonably good. You can then use these assignments to estimate (a) the topic mixture of each document (by counting the proportion of words assigned to each topic within that document) and (b) the words associated with each topic (by counting the proportion of words assigned to each topic overall).</p></li>
</ol>
<p>(This explanation was adapted from <a href="https://wiki.ubc.ca/Course:CPSC522/Latent_Dirichlet_Allocation#cite_note-rcode-4">here</a>.) Let’s explore the topics produced:</p>
<div class="sourceCode" id="cb190"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/labelTopics.html">labelTopics</a></span><span class="op">(</span><span class="va">stm_us_pres</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Topic 1 Top Words:
##       Highest Prob: us, new, let, nation, world, can, america 
##       FREX: let, centuri, togeth, dream, new, promis, weak 
##       Lift: 19th, 200th, 20th, adventur, angri, catch, caught 
##       Score: role, dream, abroad, third, explor, shape, proud 
## Topic 2 Top Words:
##       Highest Prob: us, new, can, nation, work, world, day 
##       FREX: friend, mr, thing, breez, blow, word, fact 
##       Lift: breez, addict, alloc, assistanc, bacteria, bicentenni, bipartisanship 
##       Score: breez, crucial, blow, manger, page, thank, sometim 
## Topic 3 Top Words:
##       Highest Prob: constitut, state, govern, peopl, shall, can, law 
##       FREX: case, constitut, slave, union, territori, slaveri, perpetu 
##       Lift: abli, acting, adduc, afloat, alleg, altern, anarchi 
##       Score: case, slaveri, territori, slave, invas, provis, fli 
## Topic 4 Top Words:
##       Highest Prob: nation, peopl, must, us, world, can, govern 
##       FREX: activ, republ, task, industri, confid, inspir, normal 
##       Lift: stricken, unshaken, abdic, abject, abnorm, acclaim, afresh 
##       Score: normal, activ, amid, readjust, self-reli, relationship, unshaken 
## Topic 5 Top Words:
##       Highest Prob: govern, peopl, upon, law, state, countri, nation 
##       FREX: revenu, tariff, offic, appoint, busi, proper, consider 
##       Lift: 15th, 30th, abey, aborigin, acquaint, actuat, acut 
##       Score: revenu, legisl, enforc, polici, negro, interst, tariff 
## Topic 6 Top Words:
##       Highest Prob: nation, freedom, america, peopl, govern, know, democraci 
##       FREX: democraci, ideal, million, liberti, freedom, came, seen 
##       Lift: aught, charta, clariti, compact, constrict, counti, dire 
##       Score: democraci, paint, magna, million, excus, encount, unlimit 
## Topic 7 Top Words:
##       Highest Prob: us, must, america, nation, american, world, peopl 
##       FREX: journey, stori, generat, storm, america, job, ideal 
##       Lift: winter, afghanistan, aids, alongsid, anchor, anybodi, apathi 
##       Score: stori, journey, job, capitol, storm, thank, drift 
## Topic 8 Top Words:
##       Highest Prob: upon, nation, govern, peopl, can, shall, great 
##       FREX: enforc, counsel, organ, island, thought, upon, integr 
##       Lift: creation, cuba, eighteenth, fast, adapt, aspect, cuban 
##       Score: enforc, island, cuba, counsel, organ, eighteenth, adapt 
## Topic 9 Top Words:
##       Highest Prob: nation, peopl, world, can, peac, must, free 
##       FREX: resourc, contribut, repres, everywher, result, free, europ 
##       Lift: display, joint, likewis, philosophi, abhor, absurd, accur 
##       Score: europ, philosophi, commun, contribut, precept, tax, program 
## Topic 10 Top Words:
##       Highest Prob: us, govern, nation, peopl, world, must, american 
##       FREX: weapon, tax, believ, hero, man, reduc, dream 
##       Lift: 50th, hearten, marker, masteri, mathia, penal, rocket 
##       Score: weapon, hero, monument, nuclear, spend, tax, soviet</code></pre>
<p><em>FREX</em> weights words by both their overall frequency and how exclusive they are to the topic. <em>Lift</em> weights words by dividing by their frequency in other topics, which gives higher weight to words that appear less frequently elsewhere. Similar to Lift, <em>Score</em> divides the log frequency of a word in the topic by the log frequency of that word in other topics <a href="https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf">(Roberts et al. 2013)</a>. <a href="https://icml.cc/2012/papers/113.pdf">Bischof and Airoldi (2012)</a> show the value of using <strong>FREX</strong> over the other measures.</p>
<p>You can use the <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code> function to show the topics.</p>
<div class="sourceCode" id="cb192"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">stm_us_pres</span>, type <span class="op">=</span> <span class="st">"summary"</span>, labeltype <span class="op">=</span> <span class="st">"frex"</span><span class="op">)</span> <span class="co"># or prob, lift score</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-101-1.png" width="672"></div>
<p>Topic 5 seems to be about the economy: revenue, tariffs, etc. Topic 3 about slavery adn the Civil War. If you want to see a sample of a specific topic:</p>
<div class="sourceCode" id="cb193"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/findThoughts.html">findThoughts</a></span><span class="op">(</span><span class="va">stm_us_pres</span>, texts <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">corpus_us_pres</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://quanteda.io/reference/docnames.html">docnames</a></span><span class="op">(</span><span class="va">dfm_us_pres</span><span class="op">)</span><span class="op">]</span>, topics <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>  </span></code></pre></div>
<p>That is a long speech.</p>
<p>We can (should/must) run some diagnostics. There are two qualities that were are looking for in our model: semantic coherence and exclusivity. Exclusivity is based on the FREX labeling matrix. Semantic coherence is a criterion developed by Mimno et al. (2011) and it maximizes when the most probable words in a given topic frequently co-occur together. Mimno et al. (2011) show that the metric correlates well with human judgement of topic quality. Yet, it is fairly easy to obtain high semantic coherence so it is important to see it in tandem with exclusivity. Let’s see how exclusive are the words in each topic:</p>
<div class="sourceCode" id="cb194"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/dotchart.html">dotchart</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/exclusivity.html">exclusivity</a></span><span class="op">(</span><span class="va">stm_us_pres</span><span class="op">)</span>, labels <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-103-1.png" width="672"></div>
<p>We can also see the semantic coherence of our topics –words a topic generates should co-occur often in the same document–:</p>
<div class="sourceCode" id="cb195"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/dotchart.html">dotchart</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/semanticCoherence.html">semanticCoherence</a></span><span class="op">(</span><span class="va">stm_us_pres</span>,<span class="va">dfm_us_pres</span><span class="op">)</span>, labels <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-104-1.png" width="672"></div>
<p>We can also see the overall quality of our topic model:</p>
<div class="sourceCode" id="cb196"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/topicQuality.html">topicQuality</a></span><span class="op">(</span><span class="va">stm_us_pres</span>,<span class="va">dfm_us_pres</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  [1]  -5.287875  -9.358241 -12.913601  -2.995819  -8.562729 -11.770514
##  [7]  -4.095783  -5.495206  -5.782951  -4.769013
##  [1] 8.975480 9.330844 8.792229 8.230546 7.888169 9.119047 8.616511
##  [8] 7.905410 8.690023 8.814819</code></pre>
<div class="inline-figure"><img src="main_files/figure-html/Quality-1.png" width="672"></div>
<p>On their own, both metrics are not really useful (what do those numbers even mean?). They are useful when we are looking for the “optimal” number of topics.</p>
<div class="sourceCode" id="cb198"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">stm_us_pres_10_15_20</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/stm/man/manyTopics.html">manyTopics</a></span><span class="op">(</span><span class="va">dfm_us_pres</span>,</span>
<span>                       prevalence <span class="op">=</span> <span class="op">~</span> <span class="va">party</span>,</span>
<span>                       K <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>,<span class="fl">15</span>,<span class="fl">20</span><span class="op">)</span>, runs<span class="op">=</span><span class="fl">2</span>,</span>
<span>                       <span class="co"># max.em.its = 100, </span></span>
<span>                       init.type <span class="op">=</span> <span class="st">"Spectral"</span><span class="op">)</span> <span class="co"># It takes around 250 iterations for the model to converge. Depending on your computer, this can take a while.</span></span></code></pre></div>
<p>We can now compare the performance of each model based on their semantic coherence and exclusivity. We are looking for high exclusivity and high coherence (top-right corner):</p>
<div class="sourceCode" id="cb199"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">k_10</span> <span class="op">&lt;-</span> <span class="va">stm_us_pres_10_15_20</span><span class="op">$</span><span class="va">out</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="co"># k_10 is an stm object which can be explored and used like any other topic model. </span></span>
<span><span class="va">k_15</span> <span class="op">&lt;-</span> <span class="va">stm_us_pres_10_15_20</span><span class="op">$</span><span class="va">out</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">k_20</span> <span class="op">&lt;-</span> <span class="va">stm_us_pres_10_15_20</span><span class="op">$</span><span class="va">out</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># I will just graph the 'quality' of each model:</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/topicQuality.html">topicQuality</a></span><span class="op">(</span><span class="va">k_10</span>,<span class="va">dfm_us_pres</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  [1]  -5.287875  -9.358241 -12.913601  -2.995819  -8.562729 -11.770514
##  [7]  -4.095783  -5.495206  -5.782951  -4.769013
##  [1] 8.975480 9.330844 8.792229 8.230546 7.888169 9.119047 8.616511
##  [8] 7.905410 8.690023 8.814819</code></pre>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-106-1.png" width="672"></div>
<div class="sourceCode" id="cb201"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/topicQuality.html">topicQuality</a></span><span class="op">(</span><span class="va">k_15</span>,<span class="va">dfm_us_pres</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  [1]  -8.282551 -10.661122  -9.146329  -6.243444 -10.002100 -11.315179
##  [7]  -3.107797  -4.907182  -5.059424  -4.905652  -7.864316 -13.149897
## [13]  -6.834348 -11.917696  -4.182962
##  [1] 9.224913 9.358942 9.252240 9.185552 9.037701 9.150431 8.614509
##  [8] 8.496738 8.546778 9.138797 8.182268 9.136596 8.467905 9.641939
## [15] 8.453004</code></pre>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-106-2.png" width="672"></div>
<div class="sourceCode" id="cb203"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/stm/man/topicQuality.html">topicQuality</a></span><span class="op">(</span><span class="va">k_20</span>,<span class="va">dfm_us_pres</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  [1]  -8.136428 -22.245476 -21.390006  -6.602534 -11.543624 -10.272049
##  [7]  -3.923380  -5.506620  -7.188791 -12.486262 -10.086060 -13.443443
## [13] -15.978725 -12.256070 -10.137597 -11.231218  -6.177453  -4.358259
## [19]  -5.246579  -2.209688
##  [1] 9.488914 9.872405 9.761287 9.184162 9.370479 9.330506 9.018598
##  [8] 8.520731 8.634212 9.649024 8.306973 9.125545 8.958623 9.644274
## [15] 9.532977 8.823851 9.488908 9.220082 8.595757 8.726901</code></pre>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-106-3.png" width="672"></div>
<p>Maybe we have some theory about the difference in topic prevalence across parties. We can see the topic proportions in our topic model object:</p>
<div class="sourceCode" id="cb205"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">stm_us_pres</span><span class="op">$</span><span class="va">theta</span><span class="op">)</span></span></code></pre></div>
<pre><code>##              [,1]         [,2]         [,3]         [,4]         [,5]
## [1,] 0.0001979850 9.251664e-05 8.228013e-05 1.374029e-04 0.0003064405
## [2,] 0.0004943565 6.848981e-05 9.820101e-01 1.268903e-04 0.0165642826
## [3,] 0.0002944155 4.882956e-05 9.988036e-01 1.888195e-05 0.0005382537
## [4,] 0.1142592136 9.390427e-04 8.766105e-01 2.738605e-04 0.0030665368
## [5,] 0.0114556926 2.301045e-04 6.716342e-03 1.151595e-03 0.9771020843
## [6,] 0.0253504520 3.633666e-04 4.721880e-03 1.752615e-03 0.9609463741
##              [,6]         [,7]         [,8]         [,9]        [,10]
## [1,] 0.0001963620 1.252948e-04 9.985702e-01 1.878275e-04 1.037197e-04
## [2,] 0.0001660826 1.833598e-04 2.357889e-04 9.220995e-05 5.844376e-05
## [3,] 0.0000637886 5.100825e-05 6.868126e-05 6.709721e-05 4.546202e-05
## [4,] 0.0007906834 8.990925e-04 7.088244e-04 1.080922e-03 1.371326e-03
## [5,] 0.0005254018 4.726644e-04 8.332618e-04 8.167810e-04 6.960722e-04
## [6,] 0.0007236007 6.685461e-04 1.759546e-03 1.313855e-03 2.399765e-03</code></pre>
<p>Note that the prevalence terms <span class="math inline">\(\theta\)</span> will add to 1 within a document. That is, the term tells us the proportion of (words associated with) topics for each document:</p>
<div class="sourceCode" id="cb207"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">stm_us_pres</span><span class="op">$</span><span class="va">theta</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb209"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">stm_us_pres</span><span class="op">$</span><span class="va">theta</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>What about connecting this info to our dfm and seeing if there are differences in the proportion topic 5 (economy) is addressed by each side.</p>
<div class="sourceCode" id="cb211"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://lrberge.github.io/fixest/">fixest</a></span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Attaching package: 'fixest'</code></pre>
<pre><code>## The following object is masked from 'package:arm':
## 
##     coefplot</code></pre>
<div class="sourceCode" id="cb214"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://strengejacke.github.io/sjPlot/">sjPlot</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">us_pres_prev</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>topic5 <span class="op">=</span> <span class="va">stm_us_pres</span><span class="op">$</span><span class="va">theta</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span>, <span class="fu"><a href="https://quanteda.io/reference/docvars.html">docvars</a></span><span class="op">(</span><span class="va">dfm_us_pres</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">feols_topic5</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://lrberge.github.io/fixest/reference/feols.html">feols</a></span><span class="op">(</span><span class="va">topic5</span> <span class="op">~</span> <span class="va">party</span> , data <span class="op">=</span> <span class="va">us_pres_prev</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">feols_topic5</span>, type <span class="op">=</span> <span class="st">"pred"</span>, term <span class="op">=</span> <span class="st">"party"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>caption <span class="op">=</span> <span class="st">"Stat. Sig. at p&lt;0.1"</span>, x<span class="op">=</span><span class="st">""</span>, y<span class="op">=</span><span class="st">"Topic Prevalence"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Some of the focal terms are of type `character`. This may lead to
##   unexpected results. It is recommended to convert these variables
##   to factors before fitting the model.
##   The following variables are of type character: `party`</code></pre>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-109-1.png" width="672"></div>
<p>Seems that Republican presidents address more the economy in their speeches. Let’s plot the proportion of speeches about the economy by president:</p>
<div class="sourceCode" id="cb216"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">us_pres_prev</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="co"># Going to log the prev of topic 5 because is quite skewed but you should probably leave as is if you want to explore how topics are addressed. </span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">topic5</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">President</span>,<span class="va">topic5</span><span class="op">)</span>, color <span class="op">=</span> <span class="va">party</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"log(Theta)"</span>, y <span class="op">=</span> <span class="st">""</span>, color <span class="op">=</span> <span class="st">"Party"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_color_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/wesanderson/man/wes_palette.html">wes_palette</a></span><span class="op">(</span><span class="st">"BottleRocket2"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> </span></code></pre></div>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-110-1.png" width="672"></div>
<p>We can do something similar with the <code>stm</code> function directly. We just need to specify the functional form and add the document variables.</p>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">topics_us_pres</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/stm/man/estimateEffect.html">estimateEffect</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">5</span><span class="op">)</span> <span class="op">~</span> <span class="va">party</span>, <span class="va">stm_us_pres</span>, <span class="fu"><a href="https://quanteda.io/reference/docvars.html">docvars</a></span><span class="op">(</span><span class="va">dfm_us_pres</span><span class="op">)</span><span class="op">)</span> <span class="co"># You can compare other topics by changing c(6,9). </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">topics_us_pres</span>, <span class="st">"party"</span>, method <span class="op">=</span> <span class="st">"difference"</span>,</span>
<span>     cov.value1 <span class="op">=</span> <span class="st">"Democrat"</span>, </span>
<span>     cov.value2 <span class="op">=</span> <span class="st">"Republican"</span>,</span>
<span>     labeltype <span class="op">=</span> <span class="st">"custom"</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">.75</span>,<span class="fl">.25</span><span class="op">)</span>,</span>
<span>     custom.labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'Topic 3: Slavery'</span>, <span class="st">'Topic 5: Economy'</span><span class="op">)</span>,</span>
<span>     model <span class="op">=</span> <span class="va">stm_us_pres</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="main_files/figure-html/unnamed-chunk-111-1.png" width="672"></div>
<p>Same results, Republicans mention more Topic 5: Economy.</p>

</div>
</div>








  <div class="chapter-nav">
<div class="prev"><a href="week5.html"><span class="header-section-number">5</span> Week 5: Scaling Techniques (Unsupervised Learning I)</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#week6"><span class="header-section-number">6</span> Week 6: Scaling Techniques and Topic Modeling</a></li>
<li><a class="nav-link" href="#slides-5">Slides</a></li>
<li><a class="nav-link" href="#setup-5"><span class="header-section-number">6.1</span> Setup</a></li>
<li><a class="nav-link" href="#structural-topic-models"><span class="header-section-number">6.2</span> Structural Topic Models</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/svallejovera/cta_updated/blob/master/10-week6.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/svallejovera/cta_updated/edit/master/10-week6.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>PS9594: Computational Text Analysis</strong>" was written by Dr. Sebastián Vallejo Vera | Western University. It was last built on 2026-01-25.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
